{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/random/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/random/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/random/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/random/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/random/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/random/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# We import all our dependencies.\n",
    "from n2v.models import N2VConfig, N2V\n",
    "import numpy as np\n",
    "from n2v.utils.n2v_utils import manipulate_val_data\n",
    "from n2v.internals.N2V_DataGenerator import N2V_DataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import optimizers\n",
    "import urllib\n",
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "import keras.backend as K\n",
    "K.set_learning_phase(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(-2,2,(10, 96, 96, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'means': ['-0.0029069487592312607'],\n",
       " 'stds': ['1.1533926996216468'],\n",
       " 'n_dim': 2,\n",
       " 'axes': 'YXC',\n",
       " 'n_channel_in': 1,\n",
       " 'n_channel_out': 1,\n",
       " 'unet_residual': False,\n",
       " 'unet_n_depth': 2,\n",
       " 'unet_kern_size': 3,\n",
       " 'unet_n_first': 32,\n",
       " 'unet_last_activation': 'linear',\n",
       " 'unet_input_shape': (None, None, 1),\n",
       " 'train_loss': 'mse',\n",
       " 'train_epochs': 5,\n",
       " 'train_steps_per_epoch': 5,\n",
       " 'train_learning_rate': 0.0004,\n",
       " 'train_batch_size': 128,\n",
       " 'train_tensorboard': True,\n",
       " 'train_checkpoint': 'weights_best.h5',\n",
       " 'train_reduce_lr': {'factor': 0.5, 'patience': 10},\n",
       " 'batch_norm': True,\n",
       " 'n2v_perc_pix': 1.6,\n",
       " 'n2v_patch_shape': (64, 64),\n",
       " 'n2v_manipulator': 'uniform_withCP',\n",
       " 'n2v_neighborhood_radius': 5,\n",
       " 'probabilistic': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can increase \"train_steps_per_epoch\" to get even better results at the price of longer computation. \n",
    "config = N2VConfig(X, unet_kern_size=3, \n",
    "                   train_steps_per_epoch=5,train_epochs=5, train_loss='mse', batch_norm=True, \n",
    "                   train_batch_size=128, n2v_perc_pix=1.6, n2v_patch_shape=(64, 64), \n",
    "                   n2v_manipulator='uniform_withCP', n2v_neighborhood_radius=5)\n",
    "\n",
    "# Let's look at the parameters stored in the config-object.\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/random/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/random/.local/lib/python3.6/site-packages/n2v/models/n2v_standard.py:409: UserWarning: output path for model already exists, files may be overwritten: /media/data/Development/imagej/project/CSBDeep/CSBDeep-N2V/src/main/python/models/n2v_2D_2\n",
      "  warnings.warn('output path for model already exists, files may be overwritten: %s' % str(self.logdir.resolve()))\n"
     ]
    }
   ],
   "source": [
    "# a name used to identify the model\n",
    "model_name = 'n2v_2D_2'\n",
    "# the base directory in which our model will live\n",
    "basedir = 'models'\n",
    "# We are now creating our network model.\n",
    "model = N2V(config, model_name, basedir=basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, None, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "down_level_0_no_0 (Conv2D)      (None, None, None, 3 320         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 128         down_level_0_no_0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "down_level_0_no_1 (Conv2D)      (None, None, None, 3 9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 128         down_level_0_no_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_0 (MaxPooling2D)            (None, None, None, 3 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "down_level_1_no_0 (Conv2D)      (None, None, None, 6 18496       max_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 256         down_level_1_no_0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "down_level_1_no_1 (Conv2D)      (None, None, None, 6 36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 6 256         down_level_1_no_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_1 (MaxPooling2D)            (None, None, None, 6 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "middle_0 (Conv2D)               (None, None, None, 1 73856       max_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 512         middle_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "middle_2 (Conv2D)               (None, None, None, 6 73792       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 256         middle_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 6 0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 1 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_level_1_no_0 (Conv2D)        (None, None, None, 6 73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 6 256         up_level_1_no_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 6 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_level_1_no_2 (Conv2D)        (None, None, None, 3 18464       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 3 128         up_level_1_no_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 3 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 3 0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 6 0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_level_0_no_0 (Conv2D)        (None, None, None, 3 18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 3 128         up_level_0_no_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 3 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_level_0_no_2 (Conv2D)        (None, None, None, 3 9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 3 128         up_level_0_no_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 3 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 1 33          activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 1 0           conv2d_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 334,817\n",
      "Trainable params: 333,729\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#optimizer = optimizers.SGD(lr=0.01)\n",
    "#isinstance(optimizer, optimizers.Optimizer) or print(ValueError())\n",
    "\n",
    "tfoptimizer = tf.train.AdamOptimizer(learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-7)\n",
    "model.prepare_for_training(optimizer = optimizers.TFOptimizer(tfoptimizer))\n",
    "model.keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename_tensor_name: \"save/Const:0\"\n",
       "save_tensor_name: \"save/control_dependency:0\"\n",
       "restore_op_name: \"save/restore_all\"\n",
       "max_to_keep: 5\n",
       "keep_checkpoint_every_n_hours: 10000.0\n",
       "version: V2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss/mul:0\")\n",
    "train_op = tfoptimizer.minimize(loss, name='train')\n",
    "tf.global_variables_initializer()\n",
    "tf.train.Saver().as_saver_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for training\n",
    "#writer = tf.summary.FileWriter(\"logs\", tf.get_default_graph())\n",
    "with open('../resources/graph.pb', 'wb') as f:\n",
    "    f.write(tf.get_default_graph().as_graph_def().SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ../resources/prediction/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "# save for prediction\n",
    "import shutil\n",
    "#shutil.rmtree(\"../resources/prediction\")\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()\n",
    "    tf.tables_initializer().run()\n",
    "    var_ab = tf.variables_initializer([a, b], name=\"a_and_b\")\n",
    "    sess.run(var_ab)\n",
    "    #sess.run(tf.variables_initializer([tf.compat.v1.get_variable(\"conv2d_1/bias:0\")]))\n",
    "    sess.run(init)\n",
    "    sess.run(\"init\")\n",
    "    model_input = tf.compat.v1.saved_model.build_tensor_info(sess.graph.get_tensor_by_name('input:0'))\n",
    "    model_output = tf.compat.v1.saved_model.build_tensor_info(sess.graph.get_tensor_by_name('activation_11/Identity:0'))\n",
    "\n",
    "    signature_definition = tf.compat.v1.saved_model.build_signature_def(\n",
    "        inputs={\"input\": model_input},\n",
    "        outputs={\"output\": model_output},\n",
    "        method_name=tf.compat.v1.saved_model.signature_constants.PREDICT_METHOD_NAME)\n",
    "\n",
    "    builder = tf.compat.v1.saved_model.Builder(\"../resources/prediction\")\n",
    "    builder.add_meta_graph_and_variables(sess, [tf.compat.v1.saved_model.tag_constants.SERVING], signature_def_map={\n",
    "        tf.compat.v1.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature_definition\n",
    "    }, clear_devices=True)\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
